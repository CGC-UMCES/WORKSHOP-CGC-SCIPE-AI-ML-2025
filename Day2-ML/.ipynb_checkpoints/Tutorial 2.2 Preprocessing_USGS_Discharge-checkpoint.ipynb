{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d24bc569-3d56-4eeb-9383-85f64164e546",
   "metadata": {},
   "source": [
    "# Tutorial 2.2 Preprocessing USGS Discharge Data\n",
    "\n",
    "## 2.2.1 Introduction\n",
    "\n",
    "This notebook is **Step2** for the *Predict Future DO Tutorial Series*.\n",
    "\n",
    "We preprocess daily river discharge data from the USGS for major rivers in the Chesapeake Bay watershed.  \n",
    "The goal is to calculate accumulated flow over multiple windows (e.g., 30, 60, 90 days) to represent river influence on downstream water quality.\n",
    "\n",
    "- **USGS Discharge Data** comes from: https://waterservices.usgs.gov/\n",
    "- **Rivers in this study:** Susquehanna, Potomac, James\n",
    "\n",
    "> See map in main tutorial for station locations.  \n",
    "> Use the [USGS Water Services API Tool](https://waterservices.usgs.gov/test-tools/?service=dv&statReportType=daily) to explore/download more data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c835894-4fae-43b9-901e-e94bab39b824",
   "metadata": {},
   "source": [
    "![Model Diagram](USGS_Steamgage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38853edb-a100-4e95-99da-c37615984ae6",
   "metadata": {},
   "source": [
    "## 2.2.2 Set Up API Paths, Data Retrieval (No need to run during the workshop, you can play with this section back to home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46d2f8d0-83ca-4292-8c7e-84921c7bc32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import os\n",
    "\n",
    "# def download_usgs_discharge(gage_id, start_date, end_date):\n",
    "#     import pandas as pd\n",
    "#     import requests\n",
    "#     import io\n",
    "\n",
    "#     base_url = \"https://waterservices.usgs.gov/nwis/dv/\"\n",
    "#     params = {\n",
    "#         \"format\": \"rdb\",\n",
    "#         \"sites\": gage_id,\n",
    "#         \"startDT\": start_date,\n",
    "#         \"endDT\": end_date,\n",
    "#         \"parameterCd\": \"00060\",\n",
    "#         \"siteStatus\": \"all\"\n",
    "#     }\n",
    "\n",
    "#     response = requests.get(base_url, params=params)\n",
    "#     if response.status_code != 200:\n",
    "#         raise Exception(f\"Error downloading data for {gage_id}: {response.status_code}\")\n",
    "\n",
    "#     # Remove comment lines\n",
    "#     raw_text = \"\\n\".join([line for line in response.text.splitlines() if not line.startswith(\"#\")])\n",
    "#     df = pd.read_csv(io.StringIO(raw_text), sep=\"\\t\")\n",
    "\n",
    "#     # Debug info\n",
    "#     print(\"Returned columns:\", df.columns.tolist())\n",
    "\n",
    "#     # Find the right columns\n",
    "#     date_col = [col for col in df.columns if \"datetime\" in col.lower()]\n",
    "#     flow_col = [col for col in df.columns if \"00060\" in col and \"00003\" in col]\n",
    "\n",
    "#     if not date_col or not flow_col:\n",
    "#         raise ValueError(\"Could not find expected 'datetime' or 'discharge' column.\")\n",
    "\n",
    "#     # Extract and rename\n",
    "#     df = df[[date_col[0], flow_col[0]]].copy()\n",
    "#     df.columns = [\"date\", \"discharge\"]\n",
    "\n",
    "#     # Clean: drop non-date values like '20d'\n",
    "#     df = df[~df[\"date\"].astype(str).str.contains(\"[a-zA-Z]\")]\n",
    "#     df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "#     df = df.dropna(subset=[\"date\", \"discharge\"])\n",
    "\n",
    "#     # Final formatting\n",
    "#     df.set_index(\"date\", inplace=True)\n",
    "#     return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46742e4b-29f1-40ee-911e-30e1a10f2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of river name -> USGS gage ID\n",
    "gages = {\n",
    "    \"Susquehanna\": \"01578310\",\n",
    "    \"Potomac\": \"01646500\",\n",
    "    \"James\": \"02037500\"\n",
    "}\n",
    "\n",
    "start_date = \"1984-01-01\"\n",
    "end_date = \"2024-12-31\"\n",
    "\n",
    "# # Create a folder to save the files\n",
    "# os.makedirs(\"USGS_Raw_Daily\", exist_ok=True)\n",
    "\n",
    "# for river_name, gage_id in gages.items():\n",
    "#     print(f\"‚¨áÔ∏è Downloading {river_name} ({gage_id})...\")\n",
    "#     df_daily = download_usgs_discharge(gage_id, start_date, end_date)\n",
    "#     filename = f\"USGS_Raw_Daily/{river_name}_daily.csv\"\n",
    "#     df_daily.to_csv(filename)\n",
    "#     print(f\"‚úÖ Saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc850893-9176-4023-b8f6-9fcafb1a7d74",
   "metadata": {},
   "source": [
    "## 2.2.3 Explore Raw Discharge Data\n",
    "\n",
    "Show columns, row counts, and date range for each river file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ee66098-98f2-4c51-9898-5a0b0f2700d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ --- File: Susquehanna_daily.csv ---\n",
      "üìè Number of records: 14976\n",
      "üßæ Columns:\n",
      "['date', 'discharge']\n",
      "‚ö†Ô∏è Could not parse dates in Susquehanna_daily.csv: 'datetime'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>discharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984-01-01</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984-01-02</td>\n",
       "      <td>23700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984-01-03</td>\n",
       "      <td>32200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984-01-04</td>\n",
       "      <td>32600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984-01-05</td>\n",
       "      <td>31500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  discharge\n",
       "0  1984-01-01      25000\n",
       "1  1984-01-02      23700\n",
       "2  1984-01-03      32200\n",
       "3  1984-01-04      32600\n",
       "4  1984-01-05      31500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ --- File: James_daily.csv ---\n",
      "üìè Number of records: 14976\n",
      "üßæ Columns:\n",
      "['date', 'discharge']\n",
      "‚ö†Ô∏è Could not parse dates in James_daily.csv: 'datetime'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>discharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984-01-01</td>\n",
       "      <td>10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984-01-02</td>\n",
       "      <td>9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984-01-03</td>\n",
       "      <td>8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984-01-04</td>\n",
       "      <td>7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984-01-05</td>\n",
       "      <td>6800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  discharge\n",
       "0  1984-01-01      10500\n",
       "1  1984-01-02       9300\n",
       "2  1984-01-03       8200\n",
       "3  1984-01-04       7400\n",
       "4  1984-01-05       6800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ --- File: Potomac_daily.csv ---\n",
      "üìè Number of records: 14976\n",
      "üßæ Columns:\n",
      "['date', 'discharge']\n",
      "‚ö†Ô∏è Could not parse dates in Potomac_daily.csv: 'datetime'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>discharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984-01-01</td>\n",
       "      <td>15100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984-01-02</td>\n",
       "      <td>13600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984-01-03</td>\n",
       "      <td>12600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984-01-04</td>\n",
       "      <td>11600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984-01-05</td>\n",
       "      <td>11400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  discharge\n",
       "0  1984-01-01      15100\n",
       "1  1984-01-02      13600\n",
       "2  1984-01-03      12600\n",
       "3  1984-01-04      11600\n",
       "4  1984-01-05      11400"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder = \"USGS_Raw_Daily\"\n",
    "for fname in os.listdir(folder):\n",
    "    if fname.endswith(\"_daily.csv\"):\n",
    "        fpath = os.path.join(folder, fname)\n",
    "        df = pd.read_csv(fpath)\n",
    "\n",
    "        print(f\"\\nüìÇ --- File: {fname} ---\")\n",
    "        print(f\"üìè Number of records: {len(df)}\")\n",
    "        print(\"üßæ Columns:\")\n",
    "        print(df.columns.tolist())\n",
    "\n",
    "        # Try parsing dates and show date range\n",
    "        try:\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "            print(f\"üìÜ Date range: {df['datetime'].min().date()} to {df['datetime'].max().date()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not parse dates in {fname}: {e}\")\n",
    "\n",
    "        # Show a preview\n",
    "        display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ede995-67a3-4bf7-9808-5bd1479756f6",
   "metadata": {},
   "source": [
    "## 2.2.4 Calculate Accumulated Flow\n",
    "\n",
    "For each river, calculate rolling sums (30, 60, 90 days) to capture lagged influence of discharge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2714655-7066-4083-a1b8-b81a2a864a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed and saved: Susquehanna_accumulated.csv\n",
      "\n",
      "üîç Preview of Susquehanna_accumulated.csv:\n",
      "            discharge  acc_flow_30d  acc_flow_60d  acc_flow_90d\n",
      "date                                                           \n",
      "1984-07-01      44400     1455920.0     3670820.0     7550120.0\n",
      "1984-07-02      55300     1379220.0     3662020.0     7507220.0\n",
      "1984-07-03      65500     1343720.0     3659020.0     7462720.0\n",
      "1984-07-04      63800     1326920.0     3649920.0     7369520.0\n",
      "1984-07-05      58800     1315520.0     3665120.0     7136320.0\n",
      "‚úÖ Processed and saved: Potomac_accumulated.csv\n",
      "\n",
      "üîç Preview of Potomac_accumulated.csv:\n",
      "            discharge  acc_flow_30d  acc_flow_60d  acc_flow_90d\n",
      "date                                                           \n",
      "1984-07-01       4730      156620.0      730920.0     2062920.0\n",
      "1984-07-02       4950      152070.0      712870.0     2006470.0\n",
      "1984-07-03       7530      151150.0      691400.0     1960400.0\n",
      "1984-07-04      10400      153810.0      665800.0     1867800.0\n",
      "1984-07-05       8680      155320.0      643480.0     1761480.0\n",
      "‚úÖ Processed and saved: James_accumulated.csv\n",
      "\n",
      "üîç Preview of James_accumulated.csv:\n",
      "            discharge  acc_flow_30d  acc_flow_60d  acc_flow_90d\n",
      "date                                                           \n",
      "1984-07-01       2740       97550.0      467910.0     1074510.0\n",
      "1984-07-02       3520       95320.0      460430.0     1059130.0\n",
      "1984-07-03       3470       93470.0      451600.0     1045500.0\n",
      "1984-07-04       3620       92050.0      433820.0     1020020.0\n",
      "1984-07-05       3500       90930.0      419720.0      980620.0\n"
     ]
    }
   ],
   "source": [
    "def compute_accumulated_flow(df, windows=[30, 60, 90]):\n",
    "    df = df.copy()\n",
    "    df.sort_index(inplace=True)\n",
    "    for window in windows:\n",
    "        df[f'acc_flow_{window}d'] = df['discharge'].rolling(window=window, min_periods=1).sum()\n",
    "    return df\n",
    "\n",
    "os.makedirs(\"USGS_Accumulated\", exist_ok=True)\n",
    "\n",
    "for river_name in gages:\n",
    "    file_path = f\"USGS_Raw_Daily/{river_name}_daily.csv\"\n",
    "    df = pd.read_csv(file_path, parse_dates=[\"date\"], index_col=\"date\")\n",
    "    df_acc = compute_accumulated_flow(df)\n",
    "    # Filter out data before July 1, 1984\n",
    "    cutoff_date = pd.Timestamp(\"1984-07-01\")\n",
    "    df_acc = df_acc[df_acc.index >= cutoff_date]\n",
    "    df_acc.to_csv(f\"USGS_Accumulated/{river_name}_accumulated.csv\")\n",
    "    print(f\"‚úÖ Processed and saved: {river_name}_accumulated.csv\")\n",
    "    # Show preview of the accumulated flow file\n",
    "    print(f\"\\nüîç Preview of {river_name}_accumulated.csv:\")\n",
    "    print(df_acc.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee075d6-455f-402a-9732-a82c923c6feb",
   "metadata": {},
   "source": [
    "## 2.2.5 Merge Accumulated Discharge Files\n",
    "\n",
    "Join all rivers by date to make a combined discharge dataset for downstream modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a67c2301-9cf2-466c-8f74-493e20149955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined discharge saved to CleanedData/USGS_discharge.csv\n",
      "\n",
      "üîç Preview of USGS_discharge.csv:\n",
      "            James_discharge  James_acc_flow_30d  James_acc_flow_60d  \\\n",
      "date                                                                  \n",
      "1984-07-01             2740             97550.0            467910.0   \n",
      "1984-07-02             3520             95320.0            460430.0   \n",
      "1984-07-03             3470             93470.0            451600.0   \n",
      "1984-07-04             3620             92050.0            433820.0   \n",
      "1984-07-05             3500             90930.0            419720.0   \n",
      "\n",
      "            James_acc_flow_90d  Potomac_discharge  Potomac_acc_flow_30d  \\\n",
      "date                                                                      \n",
      "1984-07-01           1074510.0               4730              156620.0   \n",
      "1984-07-02           1059130.0               4950              152070.0   \n",
      "1984-07-03           1045500.0               7530              151150.0   \n",
      "1984-07-04           1020020.0              10400              153810.0   \n",
      "1984-07-05            980620.0               8680              155320.0   \n",
      "\n",
      "            Potomac_acc_flow_60d  Potomac_acc_flow_90d  Susquehanna_discharge  \\\n",
      "date                                                                            \n",
      "1984-07-01              730920.0             2062920.0                  44400   \n",
      "1984-07-02              712870.0             2006470.0                  55300   \n",
      "1984-07-03              691400.0             1960400.0                  65500   \n",
      "1984-07-04              665800.0             1867800.0                  63800   \n",
      "1984-07-05              643480.0             1761480.0                  58800   \n",
      "\n",
      "            Susquehanna_acc_flow_30d  Susquehanna_acc_flow_60d  \\\n",
      "date                                                             \n",
      "1984-07-01                 1455920.0                 3670820.0   \n",
      "1984-07-02                 1379220.0                 3662020.0   \n",
      "1984-07-03                 1343720.0                 3659020.0   \n",
      "1984-07-04                 1326920.0                 3649920.0   \n",
      "1984-07-05                 1315520.0                 3665120.0   \n",
      "\n",
      "            Susquehanna_acc_flow_90d  \n",
      "date                                  \n",
      "1984-07-01                 7550120.0  \n",
      "1984-07-02                 7507220.0  \n",
      "1984-07-03                 7462720.0  \n",
      "1984-07-04                 7369520.0  \n",
      "1984-07-05                 7136320.0  \n"
     ]
    }
   ],
   "source": [
    "# Load each river's accumulated discharge data\n",
    "james = pd.read_csv(\"USGS_Accumulated/James_accumulated.csv\", parse_dates=[\"date\"]).set_index(\"date\")\n",
    "potomac = pd.read_csv(\"USGS_Accumulated/Potomac_accumulated.csv\", parse_dates=[\"date\"]).set_index(\"date\")\n",
    "susq = pd.read_csv(\"USGS_Accumulated/Susquehanna_accumulated.csv\", parse_dates=[\"date\"]).set_index(\"date\")\n",
    "\n",
    "# Rename columns to include river name\n",
    "james = james.add_prefix(\"James_\")\n",
    "potomac = potomac.add_prefix(\"Potomac_\")\n",
    "susq = susq.add_prefix(\"Susquehanna_\")\n",
    "\n",
    "# Merge on date\n",
    "discharge_combined = james.join(potomac, how=\"outer\").join(susq, how=\"outer\")\n",
    "discharge_combined = discharge_combined.dropna(how=\"all\")\n",
    "\n",
    "# Save final combined discharge file\n",
    "os.makedirs(\"CleanedData\", exist_ok=True)\n",
    "output_path = os.path.join(\"CleanedData\", \"USGS_discharge.csv\")\n",
    "discharge_combined.to_csv(output_path)\n",
    "print(f\"‚úÖ Combined discharge saved to {output_path}\")\n",
    "\n",
    "# Preview final CSV\n",
    "print(\"\\nüîç Preview of USGS_discharge.csv:\")\n",
    "print(discharge_combined.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
